[druid] 2019-08-17 15:52:53,651 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 15:52:53,652 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 15:52:54,412 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 15:52:54,440 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 15:52:54,446 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 15:52:54,466 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:2
   [druid] 2019-08-17 15:52:54,524 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1469517044_0001
   [druid] 2019-08-17 15:52:54,636 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 15:52:54,636 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1469517044_0001
   [druid] 2019-08-17 15:52:54,637 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 15:52:54,640 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:54,641 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 15:52:54,669 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 15:52:54,669 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:54,688 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:54,692 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:54,726 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1bf731d2
   [druid] 2019-08-17 15:52:54,730 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:0+33554432
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 15:52:54,769 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 15:52:54,771 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 15:52:55,591 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15438679; bufvoid = 104857600
   [druid] 2019-08-17 15:52:55,592 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24163312(96653248); length = 2051085/6553600
   [druid] 2019-08-17 15:52:55,638 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1469517044_0001 running in uber mode : false
   [druid] 2019-08-17 15:52:55,639 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 15:52:56,113 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 15:52:56,120 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_m_000000_0' done.
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:56,127 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:56,128 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:56,128 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:56,158 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4bbe86fd
   [druid] 2019-08-17 15:52:56,159 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:33554432+32048203
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 15:52:56,166 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 15:52:56,167 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 15:52:56,640 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-08-17 15:52:56,834 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 14987889; bufvoid = 104857600
   [druid] 2019-08-17 15:52:56,835 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24264656(97058624); length = 1949741/6553600
   [druid] 2019-08-17 15:52:57,143 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 15:52:57,149 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_m_000001_0' done.
   [druid] 2019-08-17 15:52:57,150 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:57,150 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 15:52:57,151 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 15:52:57,152 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1469517044_0001_r_000000_0
   [druid] 2019-08-17 15:52:57,156 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 15:52:57,156 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 15:52:57,186 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@27952ecf
   [druid] 2019-08-17 15:52:57,188 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@38aed811
   [druid] 2019-08-17 15:52:57,195 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 15:52:57,196 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1469517044_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 15:52:57,218 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1469517044_0001_m_000001_0 decomp: 15962763 len: 15962767 to MEMORY
   [druid] 2019-08-17 15:52:57,229 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 15962763 bytes from map-output for attempt_local1469517044_0001_m_000001_0
   [druid] 2019-08-17 15:52:57,230 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 15962763, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->15962763
   [druid] 2019-08-17 15:52:57,234 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1469517044_0001_m_000000_0 decomp: 16464225 len: 16464229 to MEMORY
   [druid] 2019-08-17 15:52:57,244 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 16464225 bytes from map-output for attempt_local1469517044_0001_m_000000_0
   [druid] 2019-08-17 15:52:57,244 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 16464225, inMemoryMapOutputs.size() -> 2, commitMemory -> 15962763, usedMemory ->32426988
   [druid] 2019-08-17 15:52:57,245 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 15:52:57,245 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:57,245 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 15:52:57,254 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 2 sorted segments
   [druid] 2019-08-17 15:52:57,254 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 32426977 bytes
   [druid] 2019-08-17 15:52:57,555 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 2 segments, 32426988 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 15:52:57,555 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 32426990 bytes from disk
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 15:52:57,556 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32426982 bytes
   [druid] 2019-08-17 15:52:57,557 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:57,560 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 15:52:58,185 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1469517044_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1469517044_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 15:52:58,186 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1469517044_0001_r_000000_0' to file:/D:/out/_temporary/0/task_local1469517044_0001_r_000000
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1469517044_0001_r_000000_0' done.
   [druid] 2019-08-17 15:52:58,187 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1469517044_0001_r_000000_0
   [druid] 2019-08-17 15:52:58,187 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 15:52:58,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 15:52:58,641 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1469517044_0001 completed successfully
   [druid] 2019-08-17 15:52:58,648 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=229627183
		FILE: Number of bytes written=115882868
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1000208
		Map output records=1000208
		Map output bytes=30426568
		Map output materialized bytes=32426996
		Input split bytes=176
		Combine input records=0
		Combine output records=0
		Reduce input groups=6040
		Reduce shuffle bytes=32426996
		Reduce input records=1000208
		Reduce output records=60400
		Spilled Records=2000416
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=118
		Total committed heap usage (bytes)=2108686336
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65606731
	File Output Format Counters 
		Bytes Written=1306518
   [druid] 2019-08-17 16:00:38,230 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 16:00:38,231 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 16:00:38,898 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 16:00:38,918 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 16:00:38,924 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 16:00:38,944 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:2
   [druid] 2019-08-17 16:00:38,994 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local184718792_0001
   [druid] 2019-08-17 16:00:39,074 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 16:00:39,074 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local184718792_0001
   [druid] 2019-08-17 16:00:39,075 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 16:00:39,078 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 16:00:39,079 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 16:00:39,105 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 16:00:39,105 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local184718792_0001_m_000000_0
   [druid] 2019-08-17 16:00:39,121 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 16:00:39,125 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 16:00:39,156 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2007dc82
   [druid] 2019-08-17 16:00:39,159 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:0+33554432
   [druid] 2019-08-17 16:00:39,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 16:00:39,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 16:00:39,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 16:00:39,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 16:00:39,198 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 16:00:39,200 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 16:00:39,967 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 16:00:39,967 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 16:00:39,967 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 16:00:39,967 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 15438679; bufvoid = 104857600
   [druid] 2019-08-17 16:00:39,967 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24163312(96653248); length = 2051085/6553600
   [druid] 2019-08-17 16:00:40,076 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local184718792_0001 running in uber mode : false
   [druid] 2019-08-17 16:00:40,077 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 16:00:40,500 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 16:00:40,508 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local184718792_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 16:00:40,514 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 16:00:40,514 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local184718792_0001_m_000000_0' done.
   [druid] 2019-08-17 16:00:40,514 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local184718792_0001_m_000000_0
   [druid] 2019-08-17 16:00:40,514 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local184718792_0001_m_000001_0
   [druid] 2019-08-17 16:00:40,514 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 16:00:40,515 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 16:00:40,544 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1c4e871c
   [druid] 2019-08-17 16:00:40,546 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:33554432+32048203
   [druid] 2019-08-17 16:00:40,550 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 16:00:40,550 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 16:00:40,550 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 16:00:40,550 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 16:00:40,550 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 16:00:40,551 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 16:00:41,079 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 0%
   [druid] 2019-08-17 16:00:41,209 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 16:00:41,209 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 16:00:41,209 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 16:00:41,209 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 14987889; bufvoid = 104857600
   [druid] 2019-08-17 16:00:41,209 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 24264656(97058624); length = 1949741/6553600
   [druid] 2019-08-17 16:00:41,511 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 16:00:41,517 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local184718792_0001_m_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 16:00:41,518 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 16:00:41,518 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local184718792_0001_m_000001_0' done.
   [druid] 2019-08-17 16:00:41,518 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local184718792_0001_m_000001_0
   [druid] 2019-08-17 16:00:41,518 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 16:00:41,519 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 16:00:41,519 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local184718792_0001_r_000000_0
   [druid] 2019-08-17 16:00:41,524 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 16:00:41,524 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 16:00:41,553 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@f932d5c
   [druid] 2019-08-17 16:00:41,554 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@173fc247
   [druid] 2019-08-17 16:00:41,562 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 16:00:41,563 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local184718792_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 16:00:41,584 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local184718792_0001_m_000000_0 decomp: 16464225 len: 16464229 to MEMORY
   [druid] 2019-08-17 16:00:41,596 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 16464225 bytes from map-output for attempt_local184718792_0001_m_000000_0
   [druid] 2019-08-17 16:00:41,596 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 16464225, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->16464225
   [druid] 2019-08-17 16:00:41,600 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local184718792_0001_m_000001_0 decomp: 15962763 len: 15962767 to MEMORY
   [druid] 2019-08-17 16:00:41,611 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 15962763 bytes from map-output for attempt_local184718792_0001_m_000001_0
   [druid] 2019-08-17 16:00:41,611 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 15962763, inMemoryMapOutputs.size() -> 2, commitMemory -> 16464225, usedMemory ->32426988
   [druid] 2019-08-17 16:00:41,611 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 16:00:41,611 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 16:00:41,611 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 2 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 16:00:41,621 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 2 sorted segments
   [druid] 2019-08-17 16:00:41,622 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 2 segments left of total size: 32426977 bytes
   [druid] 2019-08-17 16:00:42,058 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 2 segments, 32426988 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 16:00:42,058 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 32426990 bytes from disk
   [druid] 2019-08-17 16:00:42,059 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 16:00:42,059 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 16:00:42,059 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 32426982 bytes
   [druid] 2019-08-17 16:00:42,060 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 16:00:42,064 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 16:00:42,668 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local184718792_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 2 / 2 copied.
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local184718792_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local184718792_0001_r_000000_0' to file:/D:/out/_temporary/0/task_local184718792_0001_r_000000
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local184718792_0001_r_000000_0' done.
   [druid] 2019-08-17 16:00:42,669 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local184718792_0001_r_000000_0
   [druid] 2019-08-17 16:00:42,671 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 16:00:43,079 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 16:00:43,080 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local184718792_0001 completed successfully
   [druid] 2019-08-17 16:00:43,104 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=229627183
		FILE: Number of bytes written=115878428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1000208
		Map output records=1000208
		Map output bytes=30426568
		Map output materialized bytes=32426996
		Input split bytes=176
		Combine input records=0
		Combine output records=0
		Reduce input groups=6040
		Reduce shuffle bytes=32426996
		Reduce input records=1000208
		Reduce output records=60400
		Spilled Records=2000416
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=109
		Total committed heap usage (bytes)=2376597504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=65606731
	File Output Format Counters 
		Bytes Written=1306518
   [druid] 2019-08-17 17:35:55,004 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:35:55,005 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:35:55,692 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:35:55,716 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:35:55,759 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:35:55,787 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:35:55,837 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1040185160_0001
   [druid] 2019-08-17 17:35:55,920 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:35:55,920 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1040185160_0001
   [druid] 2019-08-17 17:35:55,921 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:35:55,924 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:35:55,925 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:35:55,949 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:35:55,950 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1040185160_0001_m_000000_0
   [druid] 2019-08-17 17:35:55,964 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:35:55,967 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:35:56,000 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7cd7b024
   [druid] 2019-08-17 17:35:56,003 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:35:56,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:35:56,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:35:56,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:35:56,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:35:56,042 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:35:56,044 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:35:56,048 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 17:35:56,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:35:56,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:35:56,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 17:35:56,048 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 17:35:56,057 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:35:56,066 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1040185160_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:35:56,071 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 17:35:56,071 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1040185160_0001_m_000000_0' done.
   [druid] 2019-08-17 17:35:56,071 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1040185160_0001_m_000000_0
   [druid] 2019-08-17 17:35:56,072 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:35:56,073 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 17:35:56,073 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1040185160_0001_r_000000_0
   [druid] 2019-08-17 17:35:56,076 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:35:56,077 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:35:56,107 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18e19e18
   [druid] 2019-08-17 17:35:56,109 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b03e304
   [druid] 2019-08-17 17:35:56,116 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 17:35:56,117 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1040185160_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 17:35:56,145 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1040185160_0001_m_000000_0 decomp: 152 len: 156 to MEMORY
   [druid] 2019-08-17 17:35:56,150 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 152 bytes from map-output for attempt_local1040185160_0001_m_000000_0
   [druid] 2019-08-17 17:35:56,151 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 152, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->152
   [druid] 2019-08-17 17:35:56,152 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 17:35:56,152 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:35:56,152 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 17:35:56,160 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:35:56,161 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 146 bytes
   [druid] 2019-08-17 17:35:56,162 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 152 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 17:35:56,163 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 156 bytes from disk
   [druid] 2019-08-17 17:35:56,163 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 17:35:56,163 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:35:56,164 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 146 bytes
   [druid] 2019-08-17 17:35:56,164 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:35:56,167 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 17:35:56,177 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1040185160_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:35:56,178 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:35:56,178 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1040185160_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 17:35:56,179 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1040185160_0001_r_000000_0' to file:/D:/out2/_temporary/0/task_local1040185160_0001_r_000000
   [druid] 2019-08-17 17:35:56,180 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 17:35:56,180 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1040185160_0001_r_000000_0' done.
   [druid] 2019-08-17 17:35:56,180 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1040185160_0001_r_000000_0
   [druid] 2019-08-17 17:35:56,180 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 17:35:56,921 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1040185160_0001 running in uber mode : false
   [druid] 2019-08-17 17:35:56,923 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 17:35:56,924 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1040185160_0001 completed successfully
   [druid] 2019-08-17 17:35:56,936 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=892
		FILE: Number of bytes written=555170
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=156
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=156
		Reduce input records=13
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=510656512
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=54
   [druid] 2019-08-17 17:37:08,302 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:37:08,303 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:37:08,976 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:37:08,997 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:37:09,038 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:37:09,057 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:37:09,109 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local992619573_0001
   [druid] 2019-08-17 17:37:09,191 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:37:09,192 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local992619573_0001
   [druid] 2019-08-17 17:37:09,192 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:37:09,196 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:37:09,197 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:37:09,222 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:37:09,222 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local992619573_0001_m_000000_0
   [druid] 2019-08-17 17:37:09,237 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:37:09,241 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:37:09,272 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@70397afc
   [druid] 2019-08-17 17:37:09,275 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:37:09,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:37:09,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:37:09,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:37:09,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:37:09,313 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:37:09,315 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:37:09,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:37:09,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:37:09,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:37:09,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:37:09,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:37:09,337 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:37:09,338 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local992619573_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:16)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:37:10,193 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local992619573_0001 running in uber mode : false
   [druid] 2019-08-17 17:37:10,195 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:37:10,197 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local992619573_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:37:10,201 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:40:02,079 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:40:02,079 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:40:02,756 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:40:02,777 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:40:02,819 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:40:02,838 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:40:02,890 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1770106538_0001
   [druid] 2019-08-17 17:40:02,969 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:40:02,970 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1770106538_0001
   [druid] 2019-08-17 17:40:02,971 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:40:02,974 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:40:02,975 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:40:02,999 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:40:02,999 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1770106538_0001_m_000000_0
   [druid] 2019-08-17 17:40:03,013 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:40:03,017 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:40:03,047 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1651c469
   [druid] 2019-08-17 17:40:03,050 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:40:03,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:40:03,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:40:03,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:40:03,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:40:03,089 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:40:03,091 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:40:03,094 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:40:03,094 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:40:03,094 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:40:03,094 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:40:03,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:40:03,108 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:40:03,109 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1770106538_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:16)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:40:03,971 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1770106538_0001 running in uber mode : false
   [druid] 2019-08-17 17:40:03,972 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:40:03,973 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1770106538_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:40:03,975 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:44:30,975 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:44:30,976 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:45:13,259 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:45:13,260 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:45:13,951 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:45:13,972 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:45:14,012 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:45:14,032 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:2
   [druid] 2019-08-17 17:45:14,123 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local594311156_0001
   [druid] 2019-08-17 17:45:14,209 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:45:14,209 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local594311156_0001
   [druid] 2019-08-17 17:45:14,210 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:45:14,213 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:45:14,214 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:45:14,238 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:45:14,238 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local594311156_0001_m_000000_0
   [druid] 2019-08-17 17:45:14,252 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:45:14,256 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:45:14,287 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6cec6fbe
   [druid] 2019-08-17 17:45:14,290 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:0+33554432
   [druid] 2019-08-17 17:45:14,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:45:14,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:45:14,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:45:14,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:45:14,328 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:45:14,330 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:45:14,333 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:45:14,351 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local594311156_0001_m_000001_0
   [druid] 2019-08-17 17:45:14,351 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:45:14,351 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:45:14,384 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6d582140
   [druid] 2019-08-17 17:45:14,385 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:33554432+32048203
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:45:14,417 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:45:14,420 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:45:14,431 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:45:14,432 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local594311156_0001
   java.lang.Exception: java.io.IOException: Illegal partition for {"movie" (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for {"movie" (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:16)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:45:15,211 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local594311156_0001 running in uber mode : false
   [druid] 2019-08-17 17:45:15,215 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:45:15,219 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local594311156_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:45:15,230 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:46:23,252 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:46:23,253 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:46:23,934 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:46:23,954 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:46:23,995 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:46:24,014 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:2
   [druid] 2019-08-17 17:46:24,066 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1112621196_0001
   [druid] 2019-08-17 17:46:24,145 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:46:24,146 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1112621196_0001
   [druid] 2019-08-17 17:46:24,147 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:46:24,151 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:46:24,153 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:46:24,177 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:46:24,177 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1112621196_0001_m_000000_0
   [druid] 2019-08-17 17:46:24,191 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:46:24,196 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:46:24,226 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@7cd7b024
   [druid] 2019-08-17 17:46:24,229 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:0+33554432
   [druid] 2019-08-17 17:46:24,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:46:24,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:46:24,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:46:24,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:46:24,266 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:46:24,268 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:46:24,271 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:46:24,286 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1112621196_0001_m_000001_0
   [druid] 2019-08-17 17:46:24,287 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:46:24,287 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:46:24,318 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6fd611e9
   [druid] 2019-08-17 17:46:24,319 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/in/rating.json:33554432+32048203
   [druid] 2019-08-17 17:46:24,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:46:24,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:46:24,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:46:24,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:46:24,351 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:46:24,352 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:46:24,354 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:46:24,366 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:46:24,367 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1112621196_0001
   java.lang.Exception: java.io.IOException: Illegal partition for {"movie" (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for {"movie" (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:17)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:46:25,147 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1112621196_0001 running in uber mode : false
   [druid] 2019-08-17 17:46:25,149 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:46:25,152 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1112621196_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:46:25,160 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:46:45,508 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:46:45,509 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:48:11,762 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:48:11,763 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:48:31,284 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:48:31,285 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:48:31,953 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:48:31,974 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:48:32,014 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:48:32,033 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:48:32,084 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local470633540_0001
   [druid] 2019-08-17 17:48:32,165 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:48:32,166 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local470633540_0001
   [druid] 2019-08-17 17:48:32,167 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:48:32,170 [Thread-3       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:48:32,171 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:48:32,195 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:48:32,196 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local470633540_0001_m_000000_0
   [druid] 2019-08-17 17:48:32,210 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:48:32,214 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:48:32,244 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@60ce7974
   [druid] 2019-08-17 17:48:32,246 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:48:32,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:48:32,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:48:32,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:48:32,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:48:32,285 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:48:32,287 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:48:32,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:48:32,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:48:32,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:48:32,291 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:48:32,300 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:48:32,305 [Thread-3       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:48:32,306 [Thread-3       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local470633540_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:17)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:48:33,167 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local470633540_0001 running in uber mode : false
   [druid] 2019-08-17 17:48:33,169 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:48:33,172 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local470633540_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:48:33,176 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:49:35,989 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:49:35,990 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:49:36,673 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:49:36,693 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:49:36,697 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:49:36,746 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:49:36,801 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local172679687_0001
   [druid] 2019-08-17 17:49:36,887 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:49:36,888 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local172679687_0001
   [druid] 2019-08-17 17:49:36,888 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:49:36,891 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:49:36,893 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:49:36,916 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:49:36,917 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local172679687_0001_m_000000_0
   [druid] 2019-08-17 17:49:36,931 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:49:36,934 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:49:36,964 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2007dc82
   [druid] 2019-08-17 17:49:36,967 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:49:37,005 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:49:37,005 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:49:37,005 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:49:37,005 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:49:37,005 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:49:37,007 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:49:37,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:49:37,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:49:37,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:49:37,010 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:49:37,019 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:49:37,023 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:49:37,025 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local172679687_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:17)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:49:37,890 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local172679687_0001 running in uber mode : false
   [druid] 2019-08-17 17:49:37,892 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:49:37,895 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local172679687_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:49:37,898 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:52:47,330 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:52:47,331 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:52:48,000 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:52:48,020 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:52:48,025 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:52:48,047 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:52:48,096 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1562253212_0001
   [druid] 2019-08-17 17:52:48,180 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:52:48,180 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1562253212_0001
   [druid] 2019-08-17 17:52:48,181 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:52:48,184 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:52:48,185 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:52:48,208 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:52:48,208 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1562253212_0001_m_000000_0
   [druid] 2019-08-17 17:52:48,224 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:52:48,228 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:52:48,259 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@41ed0bf8
   [druid] 2019-08-17 17:52:48,262 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:52:48,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:52:48,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:52:48,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:52:48,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:52:48,301 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:52:48,303 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:52:48,306 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:52:48,306 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:52:48,306 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:52:48,306 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:52:48,315 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:52:48,322 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:52:48,323 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1562253212_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:17)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:52:49,182 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1562253212_0001 running in uber mode : false
   [druid] 2019-08-17 17:52:49,184 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:52:49,187 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1562253212_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:52:49,191 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:53:23,796 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:53:23,797 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:53:24,471 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:53:24,493 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:53:24,498 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:53:24,520 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:53:24,576 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1237470441_0001
   [druid] 2019-08-17 17:53:24,654 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:53:24,654 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1237470441_0001
   [druid] 2019-08-17 17:53:24,655 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:53:24,658 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:53:24,659 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:53:24,691 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:53:24,692 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1237470441_0001_m_000000_0
   [druid] 2019-08-17 17:53:24,706 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:53:24,709 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:53:24,741 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38f7b85c
   [druid] 2019-08-17 17:53:24,744 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:53:24,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:53:24,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:53:24,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:53:24,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:53:24,784 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:53:24,786 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:53:24,789 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:53:24,789 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:53:24,789 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:53:24,789 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:53:24,799 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:53:24,805 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:53:24,806 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1237470441_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:17)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:53:25,656 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1237470441_0001 running in uber mode : false
   [druid] 2019-08-17 17:53:25,658 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:53:25,660 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1237470441_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:53:25,663 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:55:02,643 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:55:02,644 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:55:03,314 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:55:03,334 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:55:03,339 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:55:03,363 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:55:03,413 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local792874076_0001
   [druid] 2019-08-17 17:55:03,502 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:55:03,502 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local792874076_0001
   [druid] 2019-08-17 17:55:03,503 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:55:03,506 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:55:03,507 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:55:03,533 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:55:03,534 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local792874076_0001_m_000000_0
   [druid] 2019-08-17 17:55:03,547 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:55:03,550 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:55:03,582 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6e00d3b6
   [druid] 2019-08-17 17:55:03,585 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:55:03,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:55:03,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:55:03,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:55:03,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:55:03,625 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:55:03,627 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:55:03,630 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:55:03,630 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:55:03,630 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 30; bufvoid = 104857600
   [druid] 2019-08-17 17:55:03,630 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214388(104857552); length = 9/6553600
   [druid] 2019-08-17 17:55:03,639 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:55:03,643 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:55:03,644 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local792874076_0001
   java.lang.Exception: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:522)
Caused by: java.io.IOException: Illegal partition for 136455 (4)
	at org.apache.hadoop.mapred.MapTask$MapOutputBuffer.collect(MapTask.java:1082)
	at org.apache.hadoop.mapred.MapTask$NewOutputCollector.write(MapTask.java:715)
	at org.apache.hadoop.mapreduce.task.TaskInputOutputContextImpl.write(TaskInputOutputContextImpl.java:89)
	at org.apache.hadoop.mapreduce.lib.map.WrappedMapper$Context.write(WrappedMapper.java:112)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:18)
	at com.qf.bigdata.phoneProvince.AMap.map(AMap.java:10)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:787)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:341)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:243)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 17:55:04,503 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local792874076_0001 running in uber mode : false
   [druid] 2019-08-17 17:55:04,506 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 0% reduce 0%
   [druid] 2019-08-17 17:55:04,510 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local792874076_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 17:55:04,516 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 0
   [druid] 2019-08-17 17:56:09,737 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 17:56:09,738 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 17:56:10,419 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 17:56:10,438 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 17:56:10,442 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 17:56:10,462 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 17:56:10,516 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1084951570_0001
   [druid] 2019-08-17 17:56:10,597 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 17:56:10,598 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1084951570_0001
   [druid] 2019-08-17 17:56:10,598 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 17:56:10,601 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,602 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 17:56:10,626 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 17:56:10,626 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:10,642 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,645 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:56:10,677 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@2007dc82
   [druid] 2019-08-17 17:56:10,680 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 17:56:10,719 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 17:56:10,719 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 17:56:10,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 17:56:10,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 17:56:10,720 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 17:56:10,721 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 17:56:10,726 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 17:56:10,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 17:56:10,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 17:56:10,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 17:56:10,726 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 17:56:10,735 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 17:56:10,744 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1084951570_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:56:10,749 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 17:56:10,749 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1084951570_0001_m_000000_0' done.
   [druid] 2019-08-17 17:56:10,749 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:10,749 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 17:56:10,751 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 17:56:10,751 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1084951570_0001_r_000000_0
   [druid] 2019-08-17 17:56:10,755 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,755 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:56:10,787 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5174ae7
   [druid] 2019-08-17 17:56:10,788 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1024c0ac
   [druid] 2019-08-17 17:56:10,795 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 17:56:10,797 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1084951570_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 17:56:10,822 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1084951570_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 17:56:10,826 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:10,827 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 17:56:10,828 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 17:56:10,828 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,828 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 17:56:10,838 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,838 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 17:56:10,842 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 17:56:10,842 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 17:56:10,843 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 17:56:10,843 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,844 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 17:56:10,844 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,847 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 17:56:10,858 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1084951570_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:56:10,859 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,861 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1084951570_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 17:56:10,862 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1084951570_0001_r_000000_0' to file:/D:/out2/_temporary/0/task_local1084951570_0001_r_000000
   [druid] 2019-08-17 17:56:10,862 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 17:56:10,862 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1084951570_0001_r_000000_0' done.
   [druid] 2019-08-17 17:56:10,862 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1084951570_0001_r_000000_0
   [druid] 2019-08-17 17:56:10,862 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1084951570_0001_r_000001_0
   [druid] 2019-08-17 17:56:10,863 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,864 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:56:10,897 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@37faa806
   [druid] 2019-08-17 17:56:10,897 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@47d61646
   [druid] 2019-08-17 17:56:10,898 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 17:56:10,898 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1084951570_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 17:56:10,901 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1084951570_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 17:56:10,902 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:10,902 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 17:56:10,902 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 17:56:10,902 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,902 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 17:56:10,908 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,908 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 17:56:10,911 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 17:56:10,912 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 17:56:10,912 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 17:56:10,912 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,912 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 17:56:10,912 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,921 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1084951570_0001_r_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:56:10,922 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,922 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1084951570_0001_r_000001_0 is allowed to commit now
   [druid] 2019-08-17 17:56:10,923 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1084951570_0001_r_000001_0' to file:/D:/out2/_temporary/0/task_local1084951570_0001_r_000001
   [druid] 2019-08-17 17:56:10,923 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 17:56:10,923 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1084951570_0001_r_000001_0' done.
   [druid] 2019-08-17 17:56:10,923 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1084951570_0001_r_000001_0
   [druid] 2019-08-17 17:56:10,923 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1084951570_0001_r_000002_0
   [druid] 2019-08-17 17:56:10,924 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,924 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:56:10,956 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@630ab68d
   [druid] 2019-08-17 17:56:10,956 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1499e88c
   [druid] 2019-08-17 17:56:10,956 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 17:56:10,957 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1084951570_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 17:56:10,959 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1084951570_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 17:56:10,959 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:10,959 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 17:56:10,960 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 17:56:10,960 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,960 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 17:56:10,965 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,965 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 17:56:10,968 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 17:56:10,968 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 17:56:10,969 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 17:56:10,969 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:10,969 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 17:56:10,969 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,971 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1084951570_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:56:10,972 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:10,972 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1084951570_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 17:56:10,973 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1084951570_0001_r_000002_0' to file:/D:/out2/_temporary/0/task_local1084951570_0001_r_000002
   [druid] 2019-08-17 17:56:10,973 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 17:56:10,973 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1084951570_0001_r_000002_0' done.
   [druid] 2019-08-17 17:56:10,973 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1084951570_0001_r_000002_0
   [druid] 2019-08-17 17:56:10,973 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1084951570_0001_r_000003_0
   [druid] 2019-08-17 17:56:10,974 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 17:56:10,974 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 17:56:11,005 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a801515
   [druid] 2019-08-17 17:56:11,005 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@c886216
   [druid] 2019-08-17 17:56:11,006 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 17:56:11,006 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1084951570_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 17:56:11,009 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1084951570_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 17:56:11,009 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1084951570_0001_m_000000_0
   [druid] 2019-08-17 17:56:11,009 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 17:56:11,009 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 17:56:11,010 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:11,010 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 17:56:11,014 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:11,015 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 17:56:11,018 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 17:56:11,018 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 17:56:11,018 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 17:56:11,018 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 17:56:11,019 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 17:56:11,019 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:11,026 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1084951570_0001_r_000003_0 is done. And is in the process of committing
   [druid] 2019-08-17 17:56:11,026 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 17:56:11,026 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1084951570_0001_r_000003_0 is allowed to commit now
   [druid] 2019-08-17 17:56:11,027 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1084951570_0001_r_000003_0' to file:/D:/out2/_temporary/0/task_local1084951570_0001_r_000003
   [druid] 2019-08-17 17:56:11,028 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 17:56:11,028 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1084951570_0001_r_000003_0' done.
   [druid] 2019-08-17 17:56:11,028 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1084951570_0001_r_000003_0
   [druid] 2019-08-17 17:56:11,028 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 17:56:11,599 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1084951570_0001 running in uber mode : false
   [druid] 2019-08-17 17:56:11,603 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 17:56:11,605 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1084951570_0001 completed successfully
   [druid] 2019-08-17 17:56:11,631 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=4171
		FILE: Number of bytes written=1388646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=174
		Reduce input records=13
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1276641280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=86
   [druid] 2019-08-17 18:08:44,776 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:08:44,777 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:08:45,453 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:08:45,474 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:08:45,479 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:08:45,500 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:08:45,550 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local557296335_0001
   [druid] 2019-08-17 18:08:45,634 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:08:45,635 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local557296335_0001
   [druid] 2019-08-17 18:08:45,635 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:08:45,638 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:45,639 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:08:45,669 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:08:45,669 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:45,686 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:45,690 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:08:45,724 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@4468efa7
   [druid] 2019-08-17 18:08:45,728 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:08:45,766 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:08:45,766 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:08:45,766 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:08:45,766 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:08:45,766 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:08:45,768 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:08:45,773 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:08:45,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:08:45,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:08:45,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:08:45,773 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:08:45,782 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:08:45,786 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local557296335_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:08:45,792 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:08:45,792 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local557296335_0001_m_000000_0' done.
   [druid] 2019-08-17 18:08:45,792 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:45,792 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:08:45,794 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:08:45,794 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local557296335_0001_r_000000_0
   [druid] 2019-08-17 18:08:45,797 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:45,798 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:08:45,827 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@10b14213
   [druid] 2019-08-17 18:08:45,829 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@230c5b76
   [druid] 2019-08-17 18:08:45,836 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:08:45,837 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local557296335_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:08:45,861 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local557296335_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:08:45,865 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:45,866 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:08:45,867 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:08:45,867 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,867 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:08:45,875 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,875 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:08:45,876 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:08:45,877 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:08:45,878 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:08:45,878 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,879 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:08:45,879 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,881 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:08:45,888 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local557296335_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:08:45,889 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,889 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local557296335_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:08:45,890 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local557296335_0001_r_000000_0' to file:/D:/out3/_temporary/0/task_local557296335_0001_r_000000
   [druid] 2019-08-17 18:08:45,891 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:08:45,891 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local557296335_0001_r_000000_0' done.
   [druid] 2019-08-17 18:08:45,891 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local557296335_0001_r_000000_0
   [druid] 2019-08-17 18:08:45,891 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local557296335_0001_r_000001_0
   [druid] 2019-08-17 18:08:45,892 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:45,892 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:08:45,928 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@640c92a9
   [druid] 2019-08-17 18:08:45,928 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@223d6cb4
   [druid] 2019-08-17 18:08:45,928 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:08:45,929 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local557296335_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:08:45,932 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local557296335_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:08:45,932 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:45,932 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:08:45,932 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:08:45,933 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,933 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:08:45,938 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,938 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:08:45,940 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:08:45,940 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:08:45,940 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:08:45,940 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,941 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:08:45,941 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,944 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local557296335_0001_r_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:08:45,945 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,945 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local557296335_0001_r_000001_0 is allowed to commit now
   [druid] 2019-08-17 18:08:45,946 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local557296335_0001_r_000001_0' to file:/D:/out3/_temporary/0/task_local557296335_0001_r_000001
   [druid] 2019-08-17 18:08:45,947 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:08:45,947 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local557296335_0001_r_000001_0' done.
   [druid] 2019-08-17 18:08:45,947 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local557296335_0001_r_000001_0
   [druid] 2019-08-17 18:08:45,947 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local557296335_0001_r_000002_0
   [druid] 2019-08-17 18:08:45,947 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:45,948 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:08:45,983 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1bb59ab8
   [druid] 2019-08-17 18:08:45,983 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@52241db6
   [druid] 2019-08-17 18:08:45,984 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:08:45,985 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local557296335_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:08:45,988 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local557296335_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:08:45,988 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:45,988 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:08:45,988 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:08:45,989 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:45,989 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:08:45,994 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,994 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:08:45,998 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:08:45,998 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:08:45,998 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:08:45,998 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:45,999 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:08:45,999 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:46,003 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local557296335_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:08:46,004 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:46,004 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local557296335_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:08:46,005 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local557296335_0001_r_000002_0' to file:/D:/out3/_temporary/0/task_local557296335_0001_r_000002
   [druid] 2019-08-17 18:08:46,007 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:08:46,007 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local557296335_0001_r_000002_0' done.
   [druid] 2019-08-17 18:08:46,007 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local557296335_0001_r_000002_0
   [druid] 2019-08-17 18:08:46,007 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local557296335_0001_r_000003_0
   [druid] 2019-08-17 18:08:46,008 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:08:46,008 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:08:46,038 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@5bf8e512
   [druid] 2019-08-17 18:08:46,039 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@6cafc48f
   [druid] 2019-08-17 18:08:46,039 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:08:46,039 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local557296335_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:08:46,042 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local557296335_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:08:46,042 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local557296335_0001_m_000000_0
   [druid] 2019-08-17 18:08:46,042 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:08:46,042 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:08:46,043 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:46,043 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:08:46,048 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:46,048 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:08:46,051 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:08:46,051 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:08:46,051 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:08:46,051 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:08:46,052 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:08:46,052 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:46,070 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local557296335_0001_r_000003_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:08:46,071 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:08:46,071 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local557296335_0001_r_000003_0 is allowed to commit now
   [druid] 2019-08-17 18:08:46,072 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local557296335_0001_r_000003_0' to file:/D:/out3/_temporary/0/task_local557296335_0001_r_000003
   [druid] 2019-08-17 18:08:46,072 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:08:46,072 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local557296335_0001_r_000003_0' done.
   [druid] 2019-08-17 18:08:46,072 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local557296335_0001_r_000003_0
   [druid] 2019-08-17 18:08:46,072 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:08:46,635 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local557296335_0001 running in uber mode : false
   [druid] 2019-08-17 18:08:46,638 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 18:08:46,639 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local557296335_0001 completed successfully
   [druid] 2019-08-17 18:08:46,658 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=4171
		FILE: Number of bytes written=1381236
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=174
		Reduce input records=13
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1276641280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=86
   [druid] 2019-08-17 18:11:38,915 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:11:38,916 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:11:39,586 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:11:39,606 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:11:39,611 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:11:39,631 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:11:39,683 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1368729183_0001
   [druid] 2019-08-17 18:11:39,764 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:11:39,764 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1368729183_0001
   [druid] 2019-08-17 18:11:39,765 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:11:39,768 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:39,769 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:11:39,794 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:11:39,794 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:39,809 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:39,813 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:11:39,844 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@1f0aadd
   [druid] 2019-08-17 18:11:39,847 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:11:39,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:11:39,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:11:39,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:11:39,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:11:39,885 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:11:39,887 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:11:39,892 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:11:39,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:11:39,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:11:39,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:11:39,892 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:11:39,901 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:11:39,905 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1368729183_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:11:39,911 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:11:39,911 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1368729183_0001_m_000000_0' done.
   [druid] 2019-08-17 18:11:39,911 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:39,911 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:11:39,913 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:11:39,913 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1368729183_0001_r_000000_0
   [druid] 2019-08-17 18:11:39,917 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:39,917 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:11:39,948 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3e100697
   [druid] 2019-08-17 18:11:39,949 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2414e236
   [druid] 2019-08-17 18:11:39,956 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:11:39,957 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1368729183_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:11:39,982 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1368729183_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:11:39,986 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:39,986 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:11:39,987 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:11:39,987 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:39,988 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:11:39,995 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:39,995 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:11:39,996 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:11:39,997 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:11:39,997 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:11:39,997 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:39,998 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:11:39,998 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,000 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:11:40,005 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1368729183_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:11:40,005 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,005 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1368729183_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:11:40,006 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1368729183_0001_r_000000_0' to file:/D:/out4/_temporary/0/task_local1368729183_0001_r_000000
   [druid] 2019-08-17 18:11:40,006 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:11:40,006 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1368729183_0001_r_000000_0' done.
   [druid] 2019-08-17 18:11:40,006 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1368729183_0001_r_000000_0
   [druid] 2019-08-17 18:11:40,007 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1368729183_0001_r_000001_0
   [druid] 2019-08-17 18:11:40,007 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:40,008 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:11:40,041 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46f145c5
   [druid] 2019-08-17 18:11:40,041 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51bd8994
   [druid] 2019-08-17 18:11:40,042 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:11:40,042 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1368729183_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:11:40,045 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1368729183_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:11:40,046 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:40,046 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:11:40,046 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:11:40,046 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,046 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:11:40,053 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,053 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:11:40,054 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:11:40,055 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:11:40,055 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:11:40,055 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,055 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:11:40,056 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,059 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1368729183_0001_r_000002_0
   [druid] 2019-08-17 18:11:40,059 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:40,060 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:11:40,093 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11c362ad
   [druid] 2019-08-17 18:11:40,093 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@13caba8d
   [druid] 2019-08-17 18:11:40,094 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:11:40,095 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1368729183_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:11:40,097 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1368729183_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:11:40,097 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:40,097 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:11:40,098 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:11:40,098 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,098 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:11:40,103 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,103 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:11:40,104 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:11:40,105 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:11:40,105 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:11:40,105 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,105 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:11:40,106 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,108 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1368729183_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:11:40,109 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,109 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1368729183_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:11:40,110 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1368729183_0001_r_000002_0' to file:/D:/out4/_temporary/0/task_local1368729183_0001_r_000002
   [druid] 2019-08-17 18:11:40,110 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:11:40,110 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1368729183_0001_r_000002_0' done.
   [druid] 2019-08-17 18:11:40,110 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1368729183_0001_r_000002_0
   [druid] 2019-08-17 18:11:40,110 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1368729183_0001_r_000003_0
   [druid] 2019-08-17 18:11:40,111 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:11:40,111 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:11:40,143 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@48a1feaa
   [druid] 2019-08-17 18:11:40,143 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@ef93be1
   [druid] 2019-08-17 18:11:40,144 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:11:40,145 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1368729183_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:11:40,147 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1368729183_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:11:40,147 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1368729183_0001_m_000000_0
   [druid] 2019-08-17 18:11:40,147 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:11:40,147 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:11:40,148 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,148 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:11:40,153 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,153 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:11:40,154 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:11:40,154 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:11:40,154 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:11:40,154 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:11:40,155 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:11:40,155 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:11:40,157 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:11:40,163 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1368729183_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 18:11:40,766 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1368729183_0001 running in uber mode : false
   [druid] 2019-08-17 18:11:40,770 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 50%
   [druid] 2019-08-17 18:11:40,772 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1368729183_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 18:11:40,798 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=1940
		FILE: Number of bytes written=834316
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=174
		Reduce input records=1
		Reduce output records=1
		Spilled Records=14
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=5
		Total committed heap usage (bytes)=765984768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=27
   [druid] 2019-08-17 18:13:15,262 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:13:15,263 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:13:15,944 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:13:15,968 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:13:15,973 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:13:15,996 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:13:16,047 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1509525966_0001
   [druid] 2019-08-17 18:13:16,130 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:13:16,130 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1509525966_0001
   [druid] 2019-08-17 18:13:16,131 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:13:16,134 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,135 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:13:16,159 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:13:16,160 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,177 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,180 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:13:16,211 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@33350cc6
   [druid] 2019-08-17 18:13:16,214 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:13:16,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:13:16,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:13:16,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:13:16,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:13:16,253 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:13:16,255 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:13:16,259 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:13:16,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:13:16,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:13:16,259 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:13:16,260 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:13:16,269 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:13:16,273 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1509525966_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:13:16,278 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:13:16,278 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1509525966_0001_m_000000_0' done.
   [druid] 2019-08-17 18:13:16,278 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,278 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:13:16,280 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:13:16,280 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1509525966_0001_r_000000_0
   [druid] 2019-08-17 18:13:16,284 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,284 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:13:16,314 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@6305e7bb
   [druid] 2019-08-17 18:13:16,316 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2ca72eae
   [druid] 2019-08-17 18:13:16,323 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:13:16,324 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1509525966_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:13:16,348 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1509525966_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:13:16,352 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,353 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:13:16,353 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:13:16,354 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,354 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:13:16,361 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,362 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:13:16,363 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:13:16,364 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:13:16,364 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:13:16,364 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,365 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:13:16,365 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,367 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:13:16,372 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1509525966_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:13:16,373 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,373 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1509525966_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:13:16,374 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1509525966_0001_r_000000_0' to file:/D:/out4/_temporary/0/task_local1509525966_0001_r_000000
   [druid] 2019-08-17 18:13:16,375 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:13:16,375 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1509525966_0001_r_000000_0' done.
   [druid] 2019-08-17 18:13:16,375 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1509525966_0001_r_000000_0
   [druid] 2019-08-17 18:13:16,375 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1509525966_0001_r_000001_0
   [druid] 2019-08-17 18:13:16,377 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,377 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:13:16,414 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@f194e06
   [druid] 2019-08-17 18:13:16,415 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@51988f0d
   [druid] 2019-08-17 18:13:16,415 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:13:16,416 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1509525966_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:13:16,418 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1509525966_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:13:16,419 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,419 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:13:16,419 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:13:16,420 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,420 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:13:16,425 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,425 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:13:16,426 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:13:16,427 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:13:16,427 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:13:16,427 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,428 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:13:16,428 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,430 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1509525966_0001_r_000002_0
   [druid] 2019-08-17 18:13:16,431 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,432 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:13:16,464 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@36e70368
   [druid] 2019-08-17 18:13:16,464 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@19a3cd71
   [druid] 2019-08-17 18:13:16,464 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:13:16,465 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1509525966_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:13:16,467 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1509525966_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:13:16,468 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,468 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:13:16,468 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:13:16,468 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,468 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:13:16,474 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,474 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:13:16,475 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:13:16,475 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:13:16,475 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:13:16,475 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,476 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:13:16,476 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,478 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1509525966_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:13:16,479 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,479 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1509525966_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:13:16,480 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1509525966_0001_r_000002_0' to file:/D:/out4/_temporary/0/task_local1509525966_0001_r_000002
   [druid] 2019-08-17 18:13:16,481 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:13:16,481 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1509525966_0001_r_000002_0' done.
   [druid] 2019-08-17 18:13:16,481 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1509525966_0001_r_000002_0
   [druid] 2019-08-17 18:13:16,481 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1509525966_0001_r_000003_0
   [druid] 2019-08-17 18:13:16,482 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:13:16,482 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:13:16,512 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@32857546
   [druid] 2019-08-17 18:13:16,512 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@354afe22
   [druid] 2019-08-17 18:13:16,513 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:13:16,513 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1509525966_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:13:16,515 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1509525966_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:13:16,516 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1509525966_0001_m_000000_0
   [druid] 2019-08-17 18:13:16,516 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:13:16,516 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:13:16,516 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,517 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:13:16,523 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,523 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:13:16,524 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:13:16,525 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:13:16,525 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:13:16,525 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:13:16,525 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:13:16,525 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:13:16,528 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:13:16,534 [Thread-2       ] WARN  e.hadoop.mapred.LocalJobRunner {1} - job_local1509525966_0001
   java.lang.Exception: java.lang.NullPointerException
	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:462)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:529)
Caused by: java.lang.NullPointerException
	at org.apache.hadoop.io.WritableComparator.compare(WritableComparator.java:157)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKeyValue(ReduceContextImpl.java:158)
	at org.apache.hadoop.mapreduce.task.ReduceContextImpl.nextKey(ReduceContextImpl.java:121)
	at org.apache.hadoop.mapreduce.lib.reduce.WrappedReducer$Context.nextKey(WrappedReducer.java:302)
	at org.apache.hadoop.mapreduce.Reducer.run(Reducer.java:170)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:627)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:389)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:319)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
[druid] 2019-08-17 18:13:17,132 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1509525966_0001 running in uber mode : false
   [druid] 2019-08-17 18:13:17,134 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 50%
   [druid] 2019-08-17 18:13:17,135 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1509525966_0001 failed with state FAILED due to: NA
   [druid] 2019-08-17 18:13:17,151 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=1940
		FILE: Number of bytes written=834316
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=174
		Reduce input records=1
		Reduce output records=1
		Spilled Records=14
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=765984768
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=27
   [druid] 2019-08-17 18:14:12,116 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:14:12,117 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:14:12,796 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:14:12,816 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:14:12,821 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:14:12,841 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:14:12,894 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1897019262_0001
   [druid] 2019-08-17 18:14:12,975 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:14:12,975 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1897019262_0001
   [druid] 2019-08-17 18:14:12,976 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:14:12,979 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:12,980 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:14:13,006 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:14:13,006 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,026 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:13,029 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:14:13,061 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374e6b8f
   [druid] 2019-08-17 18:14:13,064 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:14:13,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:14:13,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:14:13,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:14:13,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:14:13,103 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:14:13,105 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:14:13,109 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:14:13,110 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:14:13,110 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:14:13,110 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:14:13,110 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:14:13,120 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:14:13,124 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1897019262_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:14:13,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:14:13,130 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1897019262_0001_m_000000_0' done.
   [druid] 2019-08-17 18:14:13,130 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,130 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:14:13,132 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:14:13,132 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1897019262_0001_r_000000_0
   [druid] 2019-08-17 18:14:13,135 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:13,136 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:14:13,166 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46eed99a
   [druid] 2019-08-17 18:14:13,167 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4300b979
   [druid] 2019-08-17 18:14:13,175 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:14:13,176 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1897019262_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:14:13,201 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1897019262_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:14:13,205 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,206 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:14:13,207 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:14:13,207 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,207 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:14:13,215 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,215 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:14:13,217 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:14:13,217 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:14:13,218 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:14:13,218 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,218 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:14:13,219 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,221 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:14:13,226 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1897019262_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:14:13,227 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,228 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1897019262_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:14:13,229 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1897019262_0001_r_000000_0' to file:/D:/out4/_temporary/0/task_local1897019262_0001_r_000000
   [druid] 2019-08-17 18:14:13,229 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:14:13,229 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1897019262_0001_r_000000_0' done.
   [druid] 2019-08-17 18:14:13,230 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1897019262_0001_r_000000_0
   [druid] 2019-08-17 18:14:13,230 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1897019262_0001_r_000001_0
   [druid] 2019-08-17 18:14:13,230 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:13,231 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:14:13,264 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@793a5f50
   [druid] 2019-08-17 18:14:13,264 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@450d0f44
   [druid] 2019-08-17 18:14:13,265 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:14:13,265 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1897019262_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:14:13,268 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1897019262_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:14:13,268 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,268 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:14:13,268 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:14:13,269 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,269 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:14:13,275 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,275 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:14:13,276 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:14:13,277 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:14:13,277 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:14:13,277 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,278 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:14:13,278 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,281 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1897019262_0001_r_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:14:13,282 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,282 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1897019262_0001_r_000001_0 is allowed to commit now
   [druid] 2019-08-17 18:14:13,283 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1897019262_0001_r_000001_0' to file:/D:/out4/_temporary/0/task_local1897019262_0001_r_000001
   [druid] 2019-08-17 18:14:13,284 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:14:13,284 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1897019262_0001_r_000001_0' done.
   [druid] 2019-08-17 18:14:13,284 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1897019262_0001_r_000001_0
   [druid] 2019-08-17 18:14:13,284 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1897019262_0001_r_000002_0
   [druid] 2019-08-17 18:14:13,285 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:13,285 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:14:13,319 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f632fbe
   [druid] 2019-08-17 18:14:13,319 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12b96039
   [druid] 2019-08-17 18:14:13,320 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:14:13,321 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1897019262_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:14:13,323 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1897019262_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:14:13,324 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,324 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:14:13,324 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:14:13,325 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,325 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:14:13,330 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,330 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:14:13,333 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:14:13,334 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:14:13,334 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:14:13,334 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,335 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:14:13,335 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,337 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1897019262_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:14:13,337 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,337 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1897019262_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:14:13,338 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1897019262_0001_r_000002_0' to file:/D:/out4/_temporary/0/task_local1897019262_0001_r_000002
   [druid] 2019-08-17 18:14:13,338 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:14:13,338 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1897019262_0001_r_000002_0' done.
   [druid] 2019-08-17 18:14:13,339 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1897019262_0001_r_000002_0
   [druid] 2019-08-17 18:14:13,339 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1897019262_0001_r_000003_0
   [druid] 2019-08-17 18:14:13,339 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:14:13,339 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:14:13,368 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38e475dd
   [druid] 2019-08-17 18:14:13,369 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e5cb3a0
   [druid] 2019-08-17 18:14:13,369 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:14:13,370 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1897019262_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:14:13,372 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1897019262_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:14:13,372 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1897019262_0001_m_000000_0
   [druid] 2019-08-17 18:14:13,372 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:14:13,373 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:14:13,373 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,373 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:14:13,380 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,380 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:14:13,381 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:14:13,381 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:14:13,381 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:14:13,381 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:14:13,381 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:14:13,382 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,385 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1897019262_0001_r_000003_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:14:13,385 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:14:13,385 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1897019262_0001_r_000003_0 is allowed to commit now
   [druid] 2019-08-17 18:14:13,386 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1897019262_0001_r_000003_0' to file:/D:/out4/_temporary/0/task_local1897019262_0001_r_000003
   [druid] 2019-08-17 18:14:13,387 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:14:13,387 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1897019262_0001_r_000003_0' done.
   [druid] 2019-08-17 18:14:13,387 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1897019262_0001_r_000003_0
   [druid] 2019-08-17 18:14:13,387 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:14:13,976 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1897019262_0001 running in uber mode : false
   [druid] 2019-08-17 18:14:13,978 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 18:14:13,979 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1897019262_0001 completed successfully
   [druid] 2019-08-17 18:14:13,997 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=4171
		FILE: Number of bytes written=1388646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=174
		Reduce input records=13
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1276641280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=86
   [druid] 2019-08-17 18:17:27,110 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:17:27,111 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:17:27,778 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:17:27,797 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:17:27,802 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:17:27,822 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:17:27,873 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1846070653_0001
   [druid] 2019-08-17 18:17:27,955 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:17:27,955 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1846070653_0001
   [druid] 2019-08-17 18:17:27,956 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:17:27,958 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:27,959 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:17:27,983 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:17:27,984 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:27,999 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:28,003 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:17:28,034 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@374e6b8f
   [druid] 2019-08-17 18:17:28,037 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:17:28,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:17:28,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:17:28,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:17:28,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:17:28,076 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:17:28,078 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:17:28,083 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:17:28,083 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:17:28,083 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:17:28,083 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:17:28,083 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:17:28,092 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:17:28,096 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1846070653_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:17:28,101 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:17:28,101 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1846070653_0001_m_000000_0' done.
   [druid] 2019-08-17 18:17:28,101 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:28,102 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:17:28,103 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:17:28,104 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1846070653_0001_r_000000_0
   [druid] 2019-08-17 18:17:28,107 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:28,107 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:17:28,137 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@46eed99a
   [druid] 2019-08-17 18:17:28,139 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@4300b979
   [druid] 2019-08-17 18:17:28,146 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:17:28,146 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1846070653_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:17:28,171 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1846070653_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:17:28,175 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:28,176 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:17:28,177 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:17:28,177 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,177 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:17:28,184 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,184 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:17:28,186 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:17:28,186 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:17:28,186 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:17:28,187 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,187 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:17:28,187 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,189 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:17:28,195 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1846070653_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:17:28,195 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,196 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1846070653_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:17:28,197 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1846070653_0001_r_000000_0' to file:/D:/out4/_temporary/0/task_local1846070653_0001_r_000000
   [druid] 2019-08-17 18:17:28,198 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:17:28,198 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1846070653_0001_r_000000_0' done.
   [druid] 2019-08-17 18:17:28,198 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1846070653_0001_r_000000_0
   [druid] 2019-08-17 18:17:28,198 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1846070653_0001_r_000001_0
   [druid] 2019-08-17 18:17:28,198 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:28,199 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:17:28,232 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@793a5f50
   [druid] 2019-08-17 18:17:28,232 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@450d0f44
   [druid] 2019-08-17 18:17:28,232 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:17:28,233 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1846070653_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:17:28,235 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1846070653_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:17:28,236 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:28,236 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:17:28,236 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:17:28,237 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,237 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:17:28,242 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,242 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:17:28,243 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:17:28,244 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:17:28,244 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:17:28,244 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,244 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:17:28,244 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,250 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1846070653_0001_r_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:17:28,252 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,252 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1846070653_0001_r_000001_0 is allowed to commit now
   [druid] 2019-08-17 18:17:28,253 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1846070653_0001_r_000001_0' to file:/D:/out4/_temporary/0/task_local1846070653_0001_r_000001
   [druid] 2019-08-17 18:17:28,254 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:17:28,254 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1846070653_0001_r_000001_0' done.
   [druid] 2019-08-17 18:17:28,254 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1846070653_0001_r_000001_0
   [druid] 2019-08-17 18:17:28,254 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1846070653_0001_r_000002_0
   [druid] 2019-08-17 18:17:28,254 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:28,255 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:17:28,289 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3f632fbe
   [druid] 2019-08-17 18:17:28,289 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@12b96039
   [druid] 2019-08-17 18:17:28,291 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:17:28,291 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1846070653_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:17:28,293 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1846070653_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:17:28,294 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:28,294 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:17:28,294 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:17:28,294 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,294 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:17:28,299 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,299 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:17:28,301 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:17:28,301 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:17:28,301 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:17:28,301 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,302 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:17:28,302 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,304 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1846070653_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:17:28,305 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,305 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1846070653_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1846070653_0001_r_000002_0' to file:/D:/out4/_temporary/0/task_local1846070653_0001_r_000002
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1846070653_0001_r_000002_0' done.
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1846070653_0001_r_000002_0
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1846070653_0001_r_000003_0
   [druid] 2019-08-17 18:17:28,306 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:17:28,307 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:17:28,337 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@38e475dd
   [druid] 2019-08-17 18:17:28,337 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1e5cb3a0
   [druid] 2019-08-17 18:17:28,337 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:17:28,338 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1846070653_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:17:28,340 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1846070653_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:17:28,340 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1846070653_0001_m_000000_0
   [druid] 2019-08-17 18:17:28,341 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:17:28,341 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:17:28,341 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,341 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:17:28,351 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,351 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:17:28,352 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:17:28,353 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:17:28,353 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:17:28,353 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:17:28,353 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:17:28,353 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,356 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1846070653_0001_r_000003_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:17:28,357 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:17:28,357 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1846070653_0001_r_000003_0 is allowed to commit now
   [druid] 2019-08-17 18:17:28,358 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1846070653_0001_r_000003_0' to file:/D:/out4/_temporary/0/task_local1846070653_0001_r_000003
   [druid] 2019-08-17 18:17:28,358 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:17:28,358 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1846070653_0001_r_000003_0' done.
   [druid] 2019-08-17 18:17:28,358 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1846070653_0001_r_000003_0
   [druid] 2019-08-17 18:17:28,358 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:17:28,957 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1846070653_0001 running in uber mode : false
   [druid] 2019-08-17 18:17:28,961 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 18:17:28,963 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1846070653_0001 completed successfully
   [druid] 2019-08-17 18:17:28,983 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=4171
		FILE: Number of bytes written=1388646
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=6
		Reduce shuffle bytes=174
		Reduce input records=13
		Reduce output records=6
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1276641280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=86
   [druid] 2019-08-17 18:19:25,744 [main           ] INFO  conf.Configuration.deprecation {1} - session.id is deprecated. Instead, use dfs.metrics.session-id
   [druid] 2019-08-17 18:19:25,745 [main           ] INFO  .hadoop.metrics.jvm.JvmMetrics {1} - Initializing JVM Metrics with processName=JobTracker, sessionId=
   [druid] 2019-08-17 18:19:26,410 [main           ] WARN  .mapreduce.JobResourceUploader {1} - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
   [druid] 2019-08-17 18:19:26,431 [main           ] WARN  .mapreduce.JobResourceUploader {1} - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
   [druid] 2019-08-17 18:19:26,435 [main           ] INFO  duce.lib.input.FileInputFormat {1} - Total input paths to process : 1
   [druid] 2019-08-17 18:19:26,455 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - number of splits:1
   [druid] 2019-08-17 18:19:26,508 [main           ] INFO  .hadoop.mapreduce.JobSubmitter {1} - Submitting tokens for job: job_local1183202095_0001
   [druid] 2019-08-17 18:19:26,591 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - The url to track the job: http://localhost:8080/
   [druid] 2019-08-17 18:19:26,592 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Running job: job_local1183202095_0001
   [druid] 2019-08-17 18:19:26,592 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter set in config null
   [druid] 2019-08-17 18:19:26,596 [Thread-2       ] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,597 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
   [druid] 2019-08-17 18:19:26,630 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for map tasks
   [druid] 2019-08-17 18:19:26,630 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,646 [ask Executor #0] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,650 [ask Executor #0] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:19:26,682 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@3a296ede
   [druid] 2019-08-17 18:19:26,685 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Processing split: file:/D:/inn/phonr.txt:0+132
   [druid] 2019-08-17 18:19:26,724 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - (EQUATOR) 0 kvi 26214396(104857584)
   [druid] 2019-08-17 18:19:26,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - mapreduce.task.io.sort.mb: 100
   [druid] 2019-08-17 18:19:26,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - soft limit at 83886080
   [druid] 2019-08-17 18:19:26,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufvoid = 104857600
   [druid] 2019-08-17 18:19:26,725 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396; length = 6553600
   [druid] 2019-08-17 18:19:26,727 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
   [druid] 2019-08-17 18:19:26,731 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - 
   [druid] 2019-08-17 18:19:26,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Starting flush of map output
   [druid] 2019-08-17 18:19:26,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Spilling map output
   [druid] 2019-08-17 18:19:26,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - bufstart = 0; bufend = 124; bufvoid = 104857600
   [druid] 2019-08-17 18:19:26,732 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - kvstart = 26214396(104857584); kvend = 26214348(104857392); length = 49/6553600
   [druid] 2019-08-17 18:19:26,741 [ask Executor #0] INFO  g.apache.hadoop.mapred.MapTask {1} - Finished spill 0
   [druid] 2019-08-17 18:19:26,745 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1183202095_0001_m_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:19:26,750 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - map
   [druid] 2019-08-17 18:19:26,751 [ask Executor #0] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1183202095_0001_m_000000_0' done.
   [druid] 2019-08-17 18:19:26,751 [ask Executor #0] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,751 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - map task executor complete.
   [druid] 2019-08-17 18:19:26,753 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - Waiting for reduce tasks
   [druid] 2019-08-17 18:19:26,753 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1183202095_0001_r_000000_0
   [druid] 2019-08-17 18:19:26,756 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,757 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:19:26,788 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18e19e18
   [druid] 2019-08-17 18:19:26,790 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2b03e304
   [druid] 2019-08-17 18:19:26,797 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:19:26,798 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1183202095_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:19:26,822 [localfetcher#1 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#1 about to shuffle output of map attempt_local1183202095_0001_m_000000_0 decomp: 13 len: 17 to MEMORY
   [druid] 2019-08-17 18:19:26,827 [localfetcher#1 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 13 bytes from map-output for attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,827 [localfetcher#1 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 13, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->13
   [druid] 2019-08-17 18:19:26,828 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:19:26,828 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,829 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:19:26,837 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,837 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:19:26,838 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 13 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:19:26,839 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 17 bytes from disk
   [druid] 2019-08-17 18:19:26,839 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:19:26,841 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,842 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 6 bytes
   [druid] 2019-08-17 18:19:26,842 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,844 [pool-3-thread-1] INFO  conf.Configuration.deprecation {1} - mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords
   [druid] 2019-08-17 18:19:26,850 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1183202095_0001_r_000000_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:19:26,851 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,851 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1183202095_0001_r_000000_0 is allowed to commit now
   [druid] 2019-08-17 18:19:26,851 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1183202095_0001_r_000000_0' to file:/D:/out4/_temporary/0/task_local1183202095_0001_r_000000
   [druid] 2019-08-17 18:19:26,852 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:19:26,852 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1183202095_0001_r_000000_0' done.
   [druid] 2019-08-17 18:19:26,852 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1183202095_0001_r_000000_0
   [druid] 2019-08-17 18:19:26,852 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1183202095_0001_r_000001_0
   [druid] 2019-08-17 18:19:26,853 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,853 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:19:26,888 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@80e1f71
   [druid] 2019-08-17 18:19:26,888 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@42cf1a67
   [druid] 2019-08-17 18:19:26,889 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:19:26,889 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1183202095_0001_r_000001_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:19:26,892 [localfetcher#2 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#2 about to shuffle output of map attempt_local1183202095_0001_m_000000_0 decomp: 98 len: 102 to MEMORY
   [druid] 2019-08-17 18:19:26,893 [localfetcher#2 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 98 bytes from map-output for attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,893 [localfetcher#2 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 98, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->98
   [druid] 2019-08-17 18:19:26,893 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:19:26,893 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,893 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:19:26,899 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,899 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:19:26,900 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 98 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:19:26,900 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 102 bytes from disk
   [druid] 2019-08-17 18:19:26,900 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:19:26,900 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,901 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 90 bytes
   [druid] 2019-08-17 18:19:26,901 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,905 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1183202095_0001_r_000001_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:19:26,906 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,906 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1183202095_0001_r_000001_0 is allowed to commit now
   [druid] 2019-08-17 18:19:26,907 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1183202095_0001_r_000001_0' to file:/D:/out4/_temporary/0/task_local1183202095_0001_r_000001
   [druid] 2019-08-17 18:19:26,907 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:19:26,907 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1183202095_0001_r_000001_0' done.
   [druid] 2019-08-17 18:19:26,907 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1183202095_0001_r_000001_0
   [druid] 2019-08-17 18:19:26,907 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1183202095_0001_r_000002_0
   [druid] 2019-08-17 18:19:26,908 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,908 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:19:26,942 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@11cf7b5c
   [druid] 2019-08-17 18:19:26,943 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@61637468
   [druid] 2019-08-17 18:19:26,943 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:19:26,944 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1183202095_0001_r_000002_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:19:26,946 [localfetcher#3 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#3 about to shuffle output of map attempt_local1183202095_0001_m_000000_0 decomp: 2 len: 6 to MEMORY
   [druid] 2019-08-17 18:19:26,947 [localfetcher#3 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 2 bytes from map-output for attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,947 [localfetcher#3 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 2, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->2
   [druid] 2019-08-17 18:19:26,947 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:19:26,947 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,948 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:19:26,952 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,952 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:19:26,954 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 2 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:19:26,954 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 6 bytes from disk
   [druid] 2019-08-17 18:19:26,954 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:19:26,954 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:26,955 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 0 segments left of total size: 0 bytes
   [druid] 2019-08-17 18:19:26,955 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,959 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1183202095_0001_r_000002_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:19:26,960 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,960 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1183202095_0001_r_000002_0 is allowed to commit now
   [druid] 2019-08-17 18:19:26,961 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1183202095_0001_r_000002_0' to file:/D:/out4/_temporary/0/task_local1183202095_0001_r_000002
   [druid] 2019-08-17 18:19:26,961 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:19:26,961 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1183202095_0001_r_000002_0' done.
   [druid] 2019-08-17 18:19:26,961 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1183202095_0001_r_000002_0
   [druid] 2019-08-17 18:19:26,961 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Starting task: attempt_local1183202095_0001_r_000003_0
   [druid] 2019-08-17 18:19:26,962 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - File Output Committer Algorithm version is 1
   [druid] 2019-08-17 18:19:26,962 [pool-3-thread-1] INFO  rn.util.ProcfsBasedProcessTree {1} - ProcfsBasedProcessTree currently is supported only on Linux.
   [druid] 2019-08-17 18:19:26,992 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} -  Using ResourceCalculatorProcessTree : org.apache.hadoop.yarn.util.WindowsBasedProcessTree@18460b90
   [druid] 2019-08-17 18:19:26,992 [pool-3-thread-1] INFO  pache.hadoop.mapred.ReduceTask {1} - Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@627cecc4
   [druid] 2019-08-17 18:19:26,993 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - MergerManager: memoryLimit=1503238528, maxSingleShuffleLimit=375809632, mergeThreshold=992137472, ioSortFactor=10, memToMemMergeOutputsThreshold=10
   [druid] 2019-08-17 18:19:26,993 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - attempt_local1183202095_0001_r_000003_0 Thread started: EventFetcher for fetching Map Completion Events
   [druid] 2019-08-17 18:19:26,997 [localfetcher#4 ] INFO  educe.task.reduce.LocalFetcher {1} - localfetcher#4 about to shuffle output of map attempt_local1183202095_0001_m_000000_0 decomp: 45 len: 49 to MEMORY
   [druid] 2019-08-17 18:19:26,997 [localfetcher#4 ] INFO  .task.reduce.InMemoryMapOutput {1} - Read 45 bytes from map-output for attempt_local1183202095_0001_m_000000_0
   [druid] 2019-08-17 18:19:26,997 [localfetcher#4 ] INFO  e.task.reduce.MergeManagerImpl {1} - closeInMemoryFile -> map-output of size: 45, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->45
   [druid] 2019-08-17 18:19:26,997 [mpletion Events] INFO  educe.task.reduce.EventFetcher {1} - EventFetcher is interrupted.. Returning
   [druid] 2019-08-17 18:19:26,997 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:26,997 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
   [druid] 2019-08-17 18:19:27,002 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:27,002 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:19:27,003 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merged 1 segments, 45 bytes to disk to satisfy reduce memory limit
   [druid] 2019-08-17 18:19:27,004 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 1 files, 49 bytes from disk
   [druid] 2019-08-17 18:19:27,004 [pool-3-thread-1] INFO  e.task.reduce.MergeManagerImpl {1} - Merging 0 segments, 0 bytes from memory into reduce
   [druid] 2019-08-17 18:19:27,004 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Merging 1 sorted segments
   [druid] 2019-08-17 18:19:27,004 [pool-3-thread-1] INFO  rg.apache.hadoop.mapred.Merger {1} - Down to the last merge-pass, with 1 segments left of total size: 39 bytes
   [druid] 2019-08-17 18:19:27,004 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:27,011 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task:attempt_local1183202095_0001_r_000003_0 is done. And is in the process of committing
   [druid] 2019-08-17 18:19:27,012 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - 1 / 1 copied.
   [druid] 2019-08-17 18:19:27,012 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task attempt_local1183202095_0001_r_000003_0 is allowed to commit now
   [druid] 2019-08-17 18:19:27,013 [pool-3-thread-1] INFO  lib.output.FileOutputCommitter {1} - Saved output of task 'attempt_local1183202095_0001_r_000003_0' to file:/D:/out4/_temporary/0/task_local1183202095_0001_r_000003
   [druid] 2019-08-17 18:19:27,013 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce > reduce
   [druid] 2019-08-17 18:19:27,013 [pool-3-thread-1] INFO  org.apache.hadoop.mapred.Task  {1} - Task 'attempt_local1183202095_0001_r_000003_0' done.
   [druid] 2019-08-17 18:19:27,013 [pool-3-thread-1] INFO  e.hadoop.mapred.LocalJobRunner {1} - Finishing task: attempt_local1183202095_0001_r_000003_0
   [druid] 2019-08-17 18:19:27,013 [Thread-2       ] INFO  e.hadoop.mapred.LocalJobRunner {1} - reduce task executor complete.
   [druid] 2019-08-17 18:19:27,593 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1183202095_0001 running in uber mode : false
   [druid] 2019-08-17 18:19:27,597 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} -  map 100% reduce 100%
   [druid] 2019-08-17 18:19:27,599 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Job job_local1183202095_0001 completed successfully
   [druid] 2019-08-17 18:19:27,627 [main           ] INFO  rg.apache.hadoop.mapreduce.Job {1} - Counters: 30
	File System Counters
		FILE: Number of bytes read=4171
		FILE: Number of bytes written=1390805
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=13
		Map output records=13
		Map output bytes=124
		Map output materialized bytes=174
		Input split bytes=87
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=174
		Reduce input records=13
		Reduce output records=3
		Spilled Records=26
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=1276641280
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=132
	File Output Format Counters 
		Bytes Written=65
   